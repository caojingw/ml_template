{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is my work template for building ML models\n",
    "\n",
    "The typical ML workflow as follows:\n",
    "1. Define the Problem\n",
    "2. Data Ingestion\n",
    "3. Data Splitting: The training set is used to train the model, the validation set is used to tune hyperparameters, and the test set is used to evaluate the model's performance.\n",
    "4. Data Exploration\n",
    "5. Data Preprocessing: Missing data, imbalance, outliers, data transformation (e.g., normalization, encoding categorical variables).\n",
    "6. Feature Engineering: Engineer new features from the existing data or perform dimensionality reduction techniques like PCA if needed\n",
    "7. Feature Selection\n",
    "8. Modelling\n",
    "9. Hyperparameter Tuning\n",
    "10. Evaluating the model\n",
    "11. Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncle Steve's Amazing Do-All function\n",
    "\n",
    "It slices! It dices!\n",
    "\n",
    "In order to streamline the evaluation of each dataset, let's create an function that takes in a dataset, the name of the target column, and the name of any columsn to drop (because that's decided by the human), and then automate the rest:\n",
    "\n",
    "- Converting datatypes of the target column if necessary\n",
    "- OHE any categorical features\n",
    "- Splitting data into training and testing\n",
    "- Training and evaluating all the models/ensembles\n",
    "- Returning a list of the performance of all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-08 17:56:46.008497\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit           : 8dab54d6573f7186ff0c3b6364d5e4dd635ff3e7\n",
      "python           : 3.8.10.final.0\n",
      "python-bits      : 64\n",
      "OS               : Windows\n",
      "OS-release       : 10\n",
      "Version          : 10.0.22631\n",
      "machine          : AMD64\n",
      "processor        : Intel64 Family 6 Model 158 Stepping 9, GenuineIntel\n",
      "byteorder        : little\n",
      "LC_ALL           : None\n",
      "LANG             : None\n",
      "LOCALE           : English_Canada.1252\n",
      "\n",
      "pandas           : 1.5.2\n",
      "numpy            : 1.24.1\n",
      "pytz             : 2022.7.1\n",
      "dateutil         : 2.8.2\n",
      "setuptools       : 56.0.0\n",
      "pip              : 23.2.1\n",
      "Cython           : 0.29.14\n",
      "pytest           : None\n",
      "hypothesis       : None\n",
      "sphinx           : None\n",
      "blosc            : None\n",
      "feather          : None\n",
      "xlsxwriter       : None\n",
      "lxml.etree       : None\n",
      "html5lib         : None\n",
      "pymysql          : None\n",
      "psycopg2         : None\n",
      "jinja2           : 3.1.2\n",
      "IPython          : 8.8.0\n",
      "pandas_datareader: None\n",
      "bs4              : None\n",
      "bottleneck       : None\n",
      "brotli           : None\n",
      "fastparquet      : None\n",
      "fsspec           : 2023.6.0\n",
      "gcsfs            : None\n",
      "matplotlib       : 3.6.3\n",
      "numba            : None\n",
      "numexpr          : 2.8.5\n",
      "odfpy            : None\n",
      "openpyxl         : None\n",
      "pandas_gbq       : None\n",
      "pyarrow          : 13.0.0\n",
      "pyreadstat       : None\n",
      "pyxlsb           : None\n",
      "s3fs             : None\n",
      "scipy            : 1.10.0\n",
      "snappy           : None\n",
      "sqlalchemy       : 2.0.20\n",
      "tables           : None\n",
      "tabulate         : None\n",
      "xarray           : None\n",
      "xlrd             : None\n",
      "xlwt             : None\n",
      "zstandard        : None\n",
      "tzdata           : 2023.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.show_versions(as_json=False)\n",
    "\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Cython in c:\\users\\james\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (0.29.14)\n",
      "Requirement already satisfied: numpy in c:\\users\\james\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.8_qbz5n2kfra8p0\\localcache\\local-packages\\python38\\site-packages (1.24.1)\n",
      "Collecting auto-sklearn\n",
      "  Using cached auto-sklearn-0.15.0.tar.gz (6.5 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [17 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "        File \"C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "          return hook(config_settings)\n",
      "        File \"C:\\Users\\james\\AppData\\Local\\Temp\\pip-build-env-28je27dz\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 355, in get_requires_for_build_wheel\n",
      "          return self._get_build_requires(config_settings, requirements=['wheel'])\n",
      "        File \"C:\\Users\\james\\AppData\\Local\\Temp\\pip-build-env-28je27dz\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 325, in _get_build_requires\n",
      "          self.run_setup()\n",
      "        File \"C:\\Users\\james\\AppData\\Local\\Temp\\pip-build-env-28je27dz\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 507, in run_setup\n",
      "          super(_BuildMetaLegacyBackend, self).run_setup(setup_script=setup_script)\n",
      "        File \"C:\\Users\\james\\AppData\\Local\\Temp\\pip-build-env-28je27dz\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 341, in run_setup\n",
      "          exec(code, locals())\n",
      "        File \"<string>\", line 10, in <module>\n",
      "      ValueError: Detected unsupported operating system: win32. Please check the compability information of auto-sklearn: https://automl.github.io/auto-sklearn/master/installation.html#windows-osx-compatibility\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!apt-get install swig -y\n",
    "!pip install Cython numpy\n",
    "\n",
    "# sometimes you have to run the next command twice on colab\n",
    "# I haven't figured out why\n",
    "!pip install auto-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, VotingClassifier, BaggingClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score, precision_score, roc_auc_score\n",
    "\n",
    "import autosklearn.classification\n",
    "\n",
    "import time\n",
    "\n",
    "# Helper function\n",
    "def do_all_for_dataset(dataset_name, df, target_col, drop_cols=[]):\n",
    "\n",
    "    # If target_col is an object, convert to numbers\n",
    "    if df[target_col].dtype == 'object':\n",
    "      df[target_col] =  df[target_col].astype('category').cat.codes\n",
    "\n",
    "    # OHE all categorical columns\n",
    "    cat_cols = list(df.select_dtypes(include=['object']).columns) \n",
    "    if target_col in cat_cols: cat_cols.remove(targe_col)\n",
    "    if len(cat_cols) > 0:\n",
    "      df = pd.concat([df,pd.get_dummies(df[cat_cols])],axis=1)\n",
    "\n",
    "    # Split into X and y\n",
    "    X = df.drop(drop_cols + cat_cols + [target_col], axis=1)\n",
    "    y = df[target_col]\n",
    "\n",
    "    # Split into training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    print('Y (train) counts:')\n",
    "    print(y_train.value_counts())\n",
    "    print('Y (test) counts:')\n",
    "    print(y_test.value_counts())\n",
    "    \n",
    "    nb = GaussianNB()   \n",
    "    lr = LogisticRegression(random_state=42, solver='lbfgs', max_iter=5000)\n",
    "    dt = DecisionTreeClassifier(random_state=42)\n",
    "    knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=42, n_estimators=200)\n",
    "    ada = AdaBoostClassifier(random_state=42, n_estimators=200)\n",
    "\n",
    "    scorer = autosklearn.metrics.make_scorer(\n",
    "        'f1_score',\n",
    "        sklearn.metrics.f1_score\n",
    "    )    \n",
    "    automl = autosklearn.classification.AutoSklearnClassifier(\n",
    "          time_left_for_this_task=100, # run auto-sklearn for at most X secs\n",
    "          per_run_time_limit=15, # spend at most 60 sec for each model training\n",
    "          metric=scorer\n",
    "          )\n",
    "\n",
    "\n",
    "    est_list = [('DT', dt), ('LR', lr), ('NB', nb), ('RF', rf), ('ADA', ada)]\n",
    "       \n",
    "    dict_classifiers = {\n",
    "        \"LR\": lr, \n",
    "        \"NB\": nb,\n",
    "        \"DT\": dt,\n",
    "        \"KNN\": knn,\n",
    "        \"Voting\": VotingClassifier(estimators = est_list, voting='soft'),\n",
    "        \"Bagging\": BaggingClassifier(DecisionTreeClassifier(), n_estimators=200, random_state=42),\n",
    "        \"RF\": rf,\n",
    "        \"ExtraTrees\": ExtraTreesClassifier(random_state=42, n_estimators=200),\n",
    "        \"Adaboost\": ada,\n",
    "        \"GBC\": GradientBoostingClassifier(random_state=42, n_estimators=200),\n",
    "        \"Stacking\": StackingClassifier(estimators=est_list, final_estimator=LogisticRegression()),\n",
    "        \"automl\": automl,\n",
    "    }\n",
    "    \n",
    "    model_results = list()\n",
    "    \n",
    "    for model_name, model in dict_classifiers.items():\n",
    "        start = time.time()\n",
    "        y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "        end = time.time()\n",
    "        total = end - start\n",
    "        \n",
    "        accuracy       = accuracy_score(y_test, y_pred)\n",
    "        f1             = f1_score(y_test, y_pred)\n",
    "        recall         = recall_score(y_test, y_pred)\n",
    "        precision      = precision_score(y_test, y_pred)\n",
    "        roc_auc        = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "        df = pd.DataFrame({\"Dataset\"   : [dataset_name],\n",
    "                           \"Method\"    : [model_name],\n",
    "                           \"Time\"      : [total],\n",
    "                           \"Accuracy\"  : [accuracy],\n",
    "                           \"Recall\"    : [recall],\n",
    "                           \"Precision\" : [precision],\n",
    "                           \"F1\"        : [f1],\n",
    "                           \"AUC\"       : [roc_auc],\n",
    "                          })\n",
    "        model_results.append(df)\n",
    "   \n",
    "\n",
    "    dataset_results = pd.concat([m for m in model_results], axis = 0).reset_index()\n",
    "\n",
    "    dataset_results = dataset_results.drop(columns = \"index\",axis =1)\n",
    "    dataset_results = dataset_results.sort_values(by=['F1'], ascending=False)\n",
    "    dataset_results['Rank'] = range(1, len(dataset_results)+1)\n",
    "    \n",
    "    return dataset_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# German Credit Example\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/stepthom/869_course/main/data/GermanCredit.csv')\n",
    "r = do_all_for_dataset('GermanCredit', df, target_col='Class', drop_cols=[])\n",
    "results.append(r)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
